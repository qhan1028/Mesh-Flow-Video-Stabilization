{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from Optimization import real_time_optimize_path\n",
    "from MeshFlow import motion_propagate\n",
    "from MeshFlow import mesh_warp_frame\n",
    "from MeshFlow import generate_vertex_profiles\n",
    "\n",
    "# block of size in mesh\n",
    "PIXELS = 16\n",
    "\n",
    "# motion propagation radius\n",
    "RADIUS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(method):\n",
    "    def timed(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print('%s has taken: %.2f sec' % (method.__name__, end_time - start_time))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_performance\n",
    "def read_video(cap):\n",
    "    \"\"\"\n",
    "    @param: cap is the cv2.VideoCapture object that is\n",
    "            instantiated with given video\n",
    "\n",
    "    Returns:\n",
    "            returns mesh vertex motion vectors & \n",
    "            mesh vertex profiles \n",
    "    \"\"\"\n",
    "\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 1000,\n",
    "                        qualityLevel = 0.3,\n",
    "                        minDistance = 7,\n",
    "                        blockSize = 7 )\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                    maxLevel = 2,\n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.03))\n",
    "\n",
    "    # Take first frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # preserve aspect ratio\n",
    "    global HORIZONTAL_BORDER\n",
    "    HORIZONTAL_BORDER = 30\n",
    "\n",
    "    global VERTICAL_BORDER\n",
    "    VERTICAL_BORDER = (HORIZONTAL_BORDER*old_gray.shape[1])/old_gray.shape[0]\n",
    "\n",
    "    # motion meshes in x-direction and y-direction\n",
    "    x_motion_meshes = []; y_motion_meshes = []\n",
    "\n",
    "    # path parameters\n",
    "    x_paths = np.zeros((int(old_frame.shape[0]/PIXELS), int(old_frame.shape[1]/PIXELS), 1))\n",
    "    y_paths = np.zeros((int(old_frame.shape[0]/PIXELS), int(old_frame.shape[1]/PIXELS), 1))\n",
    "\n",
    "    frame_num = 1\n",
    "    bar = tqdm(total=frame_count, ascii=False)\n",
    "    while frame_num < frame_count:\n",
    "\n",
    "        # processing frames\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # find corners in it\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "        # estimate motion mesh for old_frame\n",
    "        x_motion_mesh, y_motion_mesh = motion_propagate(good_old, good_new, frame)\n",
    "        try:\n",
    "            x_motion_meshes = np.concatenate((x_motion_meshes, np.expand_dims(x_motion_mesh, axis=2)), axis=2)\n",
    "            y_motion_meshes = np.concatenate((y_motion_meshes, np.expand_dims(y_motion_mesh, axis=2)), axis=2)\n",
    "        except:\n",
    "            x_motion_meshes = np.expand_dims(x_motion_mesh, axis=2)\n",
    "            y_motion_meshes = np.expand_dims(y_motion_mesh, axis=2)\n",
    "\n",
    "        # generate vertex profiles\n",
    "        x_paths, y_paths = generate_vertex_profiles(x_paths, y_paths, x_motion_mesh, y_motion_mesh)\n",
    "\n",
    "        # updates frames\n",
    "        bar.update(1)\n",
    "        frame_num += 1\n",
    "        old_frame = frame.copy()\n",
    "        old_gray = frame_gray.copy()\n",
    "\n",
    "    bar.close()\n",
    "    return [x_motion_meshes, y_motion_meshes, x_paths, y_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_performance\n",
    "def stabilize(x_paths, y_paths):\n",
    "    \"\"\"\n",
    "    @param: x_paths is motion vector accumulation on \n",
    "            mesh vertices in x-direction\n",
    "    @param: y_paths is motion vector accumulation on\n",
    "            mesh vertices in y-direction\n",
    "\n",
    "    Returns:\n",
    "            returns optimized mesh vertex profiles in\n",
    "            x-direction & y-direction\n",
    "    \"\"\"\n",
    "\n",
    "    # optimize for smooth vertex profiles\n",
    "    sx_paths = real_time_optimize_path(x_paths)\n",
    "    sy_paths = real_time_optimize_path(y_paths)\n",
    "    return [sx_paths, sy_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_performance\n",
    "def plot_vertex_profiles(x_paths, sx_paths):\n",
    "    \"\"\"\n",
    "    @param: x_paths is original mesh vertex profiles\n",
    "    @param: sx_paths is optimized mesh vertex profiles\n",
    "\n",
    "    Return:\n",
    "            saves equally spaced mesh vertex profiles\n",
    "            in directory '<PWD>/results/'\n",
    "    \"\"\"\n",
    "\n",
    "    # plot some vertex profiles\n",
    "    for i in range(0, x_paths.shape[0]):\n",
    "        for j in range(0, x_paths.shape[1], 10):\n",
    "            plt.plot(x_paths[i, j, :])\n",
    "            plt.plot(sx_paths[i, j, :])\n",
    "            plt.savefig('../results/paths/'+str(i)+'_'+str(j)+'.png')\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_performance\n",
    "def get_frame_warp(x_motion_meshes, y_motion_meshes, x_paths, y_paths, sx_paths, sy_paths):\n",
    "    \"\"\"\n",
    "    @param: x_motion_meshes is the motion vectors on\n",
    "            mesh vertices in x-direction\n",
    "    @param: y_motion_meshes is the motion vectors on\n",
    "            mesh vertices in y-direction\n",
    "    @param: x_paths is motion vector accumulation on \n",
    "            mesh vertices in x-direction\n",
    "    @param: y_paths is motion vector accumulation on\n",
    "            mesh vertices in y-direction    \n",
    "    @param: sx_paths is the optimized motion vector\n",
    "            accumulation in x-direction\n",
    "    @param: sx_paths is the optimized motion vector\n",
    "            accumulation in x-direction\n",
    "\n",
    "    Returns:\n",
    "            returns a update motion mesh for each frame\n",
    "            with which that needs to be warped\n",
    "    \"\"\"\n",
    "\n",
    "    # U = P-C\n",
    "    x_motion_meshes = np.concatenate((x_motion_meshes, np.expand_dims(x_motion_meshes[:, :, -1], axis=2)), axis=2)\n",
    "    y_motion_meshes = np.concatenate((y_motion_meshes, np.expand_dims(y_motion_meshes[:, :, -1], axis=2)), axis=2)\n",
    "    new_x_motion_meshes = sx_paths-x_paths\n",
    "    new_y_motion_meshes = sy_paths-y_paths\n",
    "    return x_motion_meshes, y_motion_meshes, new_x_motion_meshes, new_y_motion_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_performance\n",
    "def generate_stabilized_video(cap, x_motion_meshes, y_motion_meshes, new_x_motion_meshes, new_y_motion_meshes, save_path):\n",
    "    \"\"\"\n",
    "    @param: cap is the cv2.VideoCapture object that is\n",
    "            instantiated with given video\n",
    "    @param: x_motion_meshes is the motion vectors on\n",
    "            mesh vertices in x-direction\n",
    "    @param: y_motion_meshes is the motion vectors on\n",
    "            mesh vertices in y-direction\n",
    "    @param: new_x_motion_meshes is the updated motion vectors \n",
    "            on mesh vertices in x-direction to be warped with\n",
    "    @param: new_y_motion_meshes is the updated motion vectors \n",
    "            on mesh vertices in y-direction to be warped with\n",
    "    \"\"\"\n",
    "    \n",
    "    # get video properties\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # generate stabilized video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(save_path, fourcc, frame_rate, (2*frame_width, frame_height))\n",
    "\n",
    "    frame_num = 0\n",
    "    bar = tqdm(total=frame_count, ascii=False)\n",
    "    \n",
    "    while frame_num < frame_count:\n",
    "        try:\n",
    "            # reconstruct from frames\n",
    "            ret, frame = cap.read()\n",
    "            x_motion_mesh = x_motion_meshes[:, :, frame_num]\n",
    "            y_motion_mesh = y_motion_meshes[:, :, frame_num]\n",
    "            new_x_motion_mesh = new_x_motion_meshes[:, :, frame_num]\n",
    "            new_y_motion_mesh = new_y_motion_meshes[:, :, frame_num]\n",
    "\n",
    "            # mesh warping\n",
    "            new_frame = mesh_warp_frame(frame, new_x_motion_mesh, new_y_motion_mesh)\n",
    "    #         new_frame = new_frame[HORIZONTAL_BORDER:-HORIZONTAL_BORDER, VERTICAL_BORDER:-VERTICAL_BORDER, :]\n",
    "            new_frame = cv2.resize(new_frame, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "            output = np.concatenate((frame, new_frame), axis=1)\n",
    "            out.write(output)\n",
    "\n",
    "            # draw old motion vectors\n",
    "            r = 5\n",
    "#             for i in range(x_motion_mesh.shape[0]):\n",
    "#                 for j in range(x_motion_mesh.shape[1]):\n",
    "#                     theta = np.arctan2(y_motion_mesh[i, j], x_motion_mesh[i, j])\n",
    "#                     cv2.line(frame, (j*PIXELS, i*PIXELS), (int(j*PIXELS+r*np.cos(theta)), int(i*PIXELS+r*np.sin(theta))), 1)\n",
    "#             cv2.imwrite('../results/old_motion_vectors/'+str(frame_num)+'.jpg', frame)\n",
    "\n",
    "            # draw new motion vectors\n",
    "#             for i in range(new_x_motion_mesh.shape[0]):\n",
    "#                 for j in range(new_x_motion_mesh.shape[1]):\n",
    "#                     theta = np.arctan2(new_y_motion_mesh[i, j], new_x_motion_mesh[i, j])\n",
    "#                     cv2.line(new_frame, (j*PIXELS, i*PIXELS), (int(j*PIXELS+r*np.cos(theta)), int(i*PIXELS+r*np.sin(theta))), 1)\n",
    "#             cv2.imwrite('../results/new_motion_vectors/'+str(frame_num)+'.jpg', new_frame)\n",
    "\n",
    "            frame_num += 1\n",
    "            bar.update(1)\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    bar.close()\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▍| 446/449 [06:34<00:02,  1.13it/s]\n",
      "  0%|                                                                                          | 0/880 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_video has taken: 394.52 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▉                                                | 351/880 [03:19<04:59,  1.77it/s]"
     ]
    }
   ],
   "source": [
    "for name in [\"running.avi\", \"parallax.avi\", \"sample.avi\", \"selfie.mp4\"]:\n",
    "    # get video properties\n",
    "    file_name = \"../data/%s\" % name\n",
    "    start_time = time.time()\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "    # propagate motion vectors and generate vertex profiles\n",
    "    x_motion_meshes, y_motion_meshes, x_paths, y_paths = read_video(cap)\n",
    "\n",
    "    # stabilize the vertex profiles\n",
    "    sx_paths, sy_paths = stabilize(x_paths, y_paths)\n",
    "\n",
    "    # visualize optimized paths\n",
    "    # plot_vertex_profiles(x_paths, sx_paths)\n",
    "\n",
    "    # get updated mesh warps\n",
    "    x_motion_meshes, y_motion_meshes, new_x_motion_meshes, new_y_motion_meshes = get_frame_warp(x_motion_meshes, y_motion_meshes, x_paths, y_paths, sx_paths, sy_paths)\n",
    "\n",
    "    # apply updated mesh warps & save the result\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "    save_path = \"../data/stabilized/%s\" % name\n",
    "    generate_stabilized_video(cap, x_motion_meshes, y_motion_meshes, new_x_motion_meshes, new_y_motion_meshes, save_path)\n",
    "\n",
    "    print('Time elapsed: ', str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
